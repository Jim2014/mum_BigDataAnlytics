---decision tree---
Decision trees are a simple hierarchically structured way to guide one’s path to a decision.
Decision tree learning is one of the most widely used techniques for classification. 
Its classification accuracy is competitive with other methods, and 
it is very efficient. 
The classification model is a tree, called decision tree

generic pseudocode
Employs the divide and conquer method
Recursively divides a training set until each division consists of examples from one class
1.Create a root node and assign all of the training data to it
2.Select the best splitting attribute
3.Add a branch to the root node for each value of the split. Split the data into mutually exclusive subsets along the lines of the specific split
4.Repeat the steps 2 and 3 for each and every leaf node until the stopping criteria is reached


C4.5	CART	CHAID


-----regress------
Find the best fitting curve for the data
When all variables are continuous variables
The model could be linear or curvilinear
Use least square error method
The dependent variable could also be binary
Measure of fit is called Coefficient of Correlation (R) 
R-sq is the fraction of variance explained by the regression model


Analysis of the strength of the linear relationship between predictor (independent) variables and outcome (dependent/criterion) variables.
In two dimensions (one predictor, one outcome variable) data can be plotted on a scatter diagram.
y=b0+b1*x
b1=sum(Xi-Xm)(Yi-Ym)/sum(Xi-Xm)2
b0=Ym-b1*Xm

Regression analysis - steps
1.ist the available Variables
2.Establish a Dependent Variable (DV) of interest
3.Find a way to predict DV using the other variables, using Least Error method
4.Use Excel, Weka or other tools

-Logistic Regression
Work with dependent variables with binary values
Effectively becomes decision model
Logistic regression take the natural logarithm (logit) of the odds of the dependent variable being a case 
logit is the continuous function upon which linear regression is conducted

-Advantages of Regression Modeling
Easy to understand 
Provide simple algebraic equations 
Goodness of fit is measured by correlation coefficient
Match and beat the predictive power of other modeling techniques
Can include any number of variables 
Regression modeling tools are pervasive such as Excel

-Disadvantages of Regression Models
Can not cover for poor data quality issues
Does not automatically take care of collinearity problems
Does not automatically take care of non-linearity
Usually works only with numeric data

------ANN-------
Artificial Neural Networks are inspired by an information processing model of mind/brain
Every neuron receives information from many other neurons, processes it, gets excited or not, and passes its state information to other neurons.
ANN are versatile systems, used for
pattern recognition, forecasting, and prediction
Classification, Regression, Clustering, Association, Optimization
In application areas like finance, marketing, manufacturing, operations, information systems, etc

Business Applications of ANN
stock price prediction
character recognition, as in recognizing hand-written text
classification problems such as loan approval

Applications Types of ANN
Classification
Feedforward networks (MLP), radial basis function, and probabilistic NN
Regression
Feedforward networks (MLP), radial basis function
Clustering
Adaptive Resonance Theory (ART) and SOM
Association
Hopfield networks

-Developing an ANN
Gather data. Divide into training data and test data. 
The training data needs to be further divided into training data and validation data. 
Select the network architecture, such as feedforward network. 
Select the algorithm, such as Multi-layer Perception. 
Set network parameters. 
Train the ANN with training data. 
Validate the model with validation data. 
Freeze the weights and other parameters. 
Test the trained network with test data.  
Deploy it when it achieves good predictive accuracy.

Advantages of ANN
Able to deal with (identify/model) highly nonlinear relationships 
Not prone to restricting normality and/or independence assumptions
Can handle variety of problem types
Usually provides better results (prediction and/or clustering) compared to its statistical counterparts
Handles both numerical and categorical variables

Disadvantages of ANN
They are deemed to be black-box solutions, lacking expandability
It is hard to find optimal values for large number of network parameters
Optimal design is still an art: requires expertise and extensive experimentation
It is hard to handle large number of variables (especially the rich nominal attributes)
Training may take a long time for large datasets; which may require case sampling


-----Cluster ------
Clustering is a technique used for automatic identification of natural groupings of things
data instances that are similar to (or near) each other are categorized into one cluster 
data instances that are very different (or far away) from each other into different clusters. 
Learns the clusters of things from past data, then assigns new instances to their cluster homes
Part of the machine-learning family 
Employs unsupervised learning
There is no output/dependent variable
Also known as segmentation

Given a representation of n objects, find K groups based on a measure of similarity such that objects within the same group are alike but the objects in different groups are not alike. 
But, what is the notion of similarity? 
What is the definition of a cluster? 
Next chart shows that clusters can differ in terms of their shape, size, and density. The presence of noise in the data makes the detection of the clusters even more difficult. 
An ideal cluster can be defined as a set of points that is compact and isolated. In reality, a cluster is a subjective entity whose significance and interpretation requires domain knowledge.

-Cluster Analysis
Used in almost every field where there is massive variety and transactions
Provide characterization, definition, and labels for populations
Identify natural groupings of customers, products, patients,  etc. 
Identify outliers in a specific domain 
Decrease the size and complexity of problems

-Cluster Analysis for Data Mining
How many clusters?
There is not a “truly optimal” way to calculate it
Heuristics are often used … ‘elbow method’
Most cluster analysis methods use a distance measure to calculate the closeness between pairs of items 
Euclidian versus Manhattan (rectilinear) distance
Inter-clusters distance  maximized
Intra-clusters distance  minimized
The quality of a clustering result depends on the algorithm, the distance function, and the application.

Analysis methods
  Statistical methods such as k-means, k-modes
  Neural networks
  Fuzzy logic (e.g., fuzzy c-means algorithm)
  Genetic algorithms 
  =Hierarchical vs Agglomerative methods
Top-down vs Bottom up algorithms

-Strengths of k-means
1.K-means is the most popular clustering algorithm.
2.Strengths: 
1)Simple: easy to understand and to implement
2)Efficient: k-means is considered a linear algorithm.
3.Weaknesses:
1)The user needs to specify k. The process may not converge. 
2)Not suitable for discovering clusters that are not hyper-ellipsoids (or hyper-spheres). 
4.No other clustering algorithm performs better in general though some may be useful for specific purposes
5.Comparing clustering algorithms is a difficult task.

-Common ways to represent clusters
Centroids of the clusters 
compute the radius and standard deviation of the cluster to determine its spread in each dimension
works well if the clusters are of the hyper-spherical shape.
Frequent values
Mainly for clustering of categorical data (e.g., k-modes clustering). 
Main method used in text clustering, where a small set of frequent words in each cluster is selected to represent the cluster.

-----Association Rule Mining-----
A very popular DM method in business
Also known as market basket analysis
Finds interesting relationships (affinities) between variables (items or events)
Assume all data are categorical.
Employs unsupervised learning
There is no output variable
Part of machine learning family
Often used as an example to describe DM to ordinary people, such as the famous “relationship between diapers and beers!”

Input: the simple point-of-sale transaction data
Output: Most frequent affinities among items 

Applications of association rule mining
In business
cross-marketing, cross-selling
store design, catalog design, e-commerce site design
optimization of online advertising
product pricing, and sales/promotion configuration
In medicine
relationships between symptoms and illnesses
diagnosis and patient characteristics and treatments
genes and their functions (genomics projects)…

X => Y [S%, C%]  
X, Y: products and/or services  
S: Support: how often X & Y go together
C: Confidence: how often Y go together with the X

-Apriori Algorithm
Finds subsets that are common to at least a minimum number of the itemsets
uses a bottom-up approach
frequent subsets are extended one item at a time (the size of frequent subsets increases from one-item subsets to two-item subsets, then three-item subsets, and so on), and 
groups of candidates at each level are tested against the data for minimum support 


